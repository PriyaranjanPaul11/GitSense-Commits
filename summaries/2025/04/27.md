# Activity Summary for 4/27/2025

## 4:08:46 PM
The code log shows development work on a Langchain project, spanning chat models and embedding models.  The project utilizes both OpenAI and HuggingFace APIs and local models.

Between 3:17 PM and 3:23 PM, two Python scripts (`4_chatmodel_hf_api.py` and `5_chatmodel_hf_local.py`) were created to interact with a HuggingFace TinyLlama chat model.  The first uses the HuggingFace API, while the second uses a locally cached model, demonstrating different deployment approaches.  Both scripts perform a simple query ("What is the capital of India").

From 3:32 PM to 3:38 PM, three scripts (`1_embedding_openai_query.py`, `2_embedding_openai_docs.py`, `3_embedding_hf_local.py`) were created to explore embedding models. `1_embedding_openai_query.py` and `2_embedding_openai_docs.py` use OpenAI's `text-embedding-3-large` model to generate embeddings for a single query and multiple documents, respectively. `3_embedding_hf_local.py` uses a Sentence Transformer model from HuggingFace (`sentence-transformers/all-MiniLM-L6-v2`) for embedding multiple documents locally.


Finally, at 3:44 PM, `4_document_similarity.py` was created. This script uses OpenAI embeddings to calculate the cosine similarity between a query ("tell me about bumrah") and a list of documents about cricketers. The script then identifies the most similar document and prints its content and similarity score, demonstrating a basic document search functionality.

A recurring pattern is the use of `load_dotenv()` to load environment variables, likely containing API keys.  The project demonstrates a comprehensive exploration of different Langchain components and model providers (OpenAI and HuggingFace), showcasing both API-based and local model usage.

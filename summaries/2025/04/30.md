# Activity Summary for 4/30/2025

## 12:47:59 PM
The log shows changes to a `.env` file containing API keys and a Python script (`4_chatmodel_hf_api.py`) utilizing the Hugging Face API for language models.

The `.env` file was updated twice on April 30th, 2025.  The first update (11:50:10 AM)  initialized API keys for OpenAI, Anthropic, Google, and Hugging Face Hub. The second update (12:41:28 PM)  modified only the Hugging Face Hub access token, suggesting a token refresh or change.

The Python script `4_chatmodel_hf_api.py` was also modified twice on the same day. The initial version (11:52:38 AM) used the `mistralai/Mistral-7B-Instruct-v0.3` model. The second version (12:45:13 PM), shortly after the `.env` file update, switched to the `TinyLlama/TinyLlama-1.1B-Chat-v1.0` model.  Both versions performed the same task: querying the model to determine India's capital and printing the result.  The modifications demonstrate a change in the selected language model within the application.


## 3:41:25 PM
The log shows development of several Python scripts interacting with Hugging Face Hub LLMs.  The primary focus is building different chatbot interfaces and exploring prompt engineering.

Initially, a `chatbot.py` file was created using `langchain_openai`. This was subsequently rewritten multiple times to utilize `langchain_community.llms.HuggingFaceHub`  for interaction with different models. The initial version used `ChatOpenAI`, then switched to `HuggingFaceHub` using `mistralai/Mistral-7B-Instruct-v0.2`, then `TinyLlama/TinyLlama-1.1B-Chat-v1.0` several times, with minor variations in code structure and how chat history was handled. The main changes involved adapting the code to correctly handle the chat history with the HuggingFaceHub models, which don't natively support chat history in the same way as `ChatOpenAI`.


A `prompt_ui.py` file was added, creating a Streamlit interface for summarizing research papers using a prompt template and the `HuggingFaceHub` LLM (`TinyLlama/TinyLlama-1.1B-Chat-v1.0`).

Finally, `temperature.py` and `messages.py` demonstrate direct use of the `HuggingFaceHub` LLM to generate a poem and handle message passing, respectively, both using  `TinyLlama/TinyLlama-1.1B-Chat-v1.0`.  The `temperature` parameter is experimented with, showing values of 0.7 and 1.5.

The significant changes occurred between approximately 2:46 PM and 3:31 PM on April 30th, 2025, primarily focused on refining the chatbot interaction and the addition of the Streamlit application.  The consistent use of `TinyLlama/TinyLlama-1.1B-Chat-v1.0` in later versions suggests a preference for this model after initial experimentation.


## 4:55:53 PM
The log shows development of two Python scripts interacting with Hugging Face Hub LLMs.

On April 30th, 2025, at 3:51 PM, `messages.py` was updated to utilize the `HuggingFaceHub` LLM from the `langchain_community` library, using the `"openai-community/gpt2"` model with specific temperature and max_new_tokens settings.  This script initiates a simple interaction, sending a system message and a human message about LangChain and printing the resulting AI response.

Later, at 4:05 PM, `chatbot.py` was created (or significantly updated).  This script also uses `HuggingFaceHub`, but this time employs the `"TinyLlama/TinyLlama-1.1B-Chat-v1.0"` model, again with temperature and max_new_tokens parameters set.  This script builds a more interactive chatbot, continuously prompting the user for input and appending responses to the chat history until the user enters 'exit'.  Both scripts share the use of `langchain_core.messages` for handling system, human, and AI messages, and both use similar settings for temperature and max_new tokens within the model kwargs.  This suggests a consistent approach to LLM interaction across both scripts.
